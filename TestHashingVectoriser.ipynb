{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "from sklearn.feature_extraction.text import HashingVectorizer, CountVectorizer\n",
    "from skl2onnx import convert_sklearn\n",
    "from skl2onnx.common.data_types import StringTensorType\n",
    "import onnx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = numpy.array([\n",
    "            \"This is the first document.\",\n",
    "            \"This document is the second document.\",\n",
    "            \"And this is the third one.\",\n",
    "            \"Is this the first document?\",\n",
    "        ]).reshape((4, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect = HashingVectorizer(ngram_range=(1, 1))\n",
    "cvect = CountVectorizer(ngram_range=(1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['and', 'document', 'first', 'is', 'one', 'second', 'the', 'third', 'this']\n"
     ]
    }
   ],
   "source": [
    "Y = cvect.fit_transform(corpus.ravel())\n",
    "print(cvect.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 1048576)\n"
     ]
    }
   ],
   "source": [
    "X = vect.fit_transform(corpus.ravel())\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/realno/sklearn-onnx/skl2onnx/operator_converters/text_vectoriser.py:171: UserWarning: Converter for TfidfVectorizer will use scikit-learn regular expression by default in version 1.6.\n",
      "  UserWarning)\n",
      "/home/realno/sklearn-onnx/skl2onnx/common/_container.py:519: UserWarning: Unable to find operator 'Tokenizer' in domain 'com.microsoft' in ONNX, op_version is forced to 1.\n",
      "  op_type, domain))\n"
     ]
    }
   ],
   "source": [
    "model_onnx_c = convert_sklearn(cvect, \"CountVectorizer\",\n",
    "                                     [(\"input\", StringTensorType([1]))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/realno/sklearn-onnx/skl2onnx/operator_converters/hashing_vectoriser.py:102: UserWarning: Converter for HashingVectorizer will use scikit-learn regular expression by default in version 1.6.\n",
      "  UserWarning)\n"
     ]
    }
   ],
   "source": [
    "model_onnx = convert_sklearn(vect, \"HashingVectorizer\",\n",
    "                                     [(\"input\", StringTensorType([1]))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ir_version: 7\n",
      "producer_name: \"skl2onnx\"\n",
      "producer_version: \"1.6.0\"\n",
      "domain: \"ai.onnx\"\n",
      "model_version: 0\n",
      "doc_string: \"\"\n",
      "graph {\n",
      "  node {\n",
      "    input: \"input\"\n",
      "    input: \"shape_tensor\"\n",
      "    output: \"flattened\"\n",
      "    name: \"Reshape\"\n",
      "    op_type: \"Reshape\"\n",
      "    domain: \"\"\n",
      "  }\n",
      "  node {\n",
      "    input: \"flattened\"\n",
      "    output: \"normalized\"\n",
      "    name: \"StringNormalizer\"\n",
      "    op_type: \"StringNormalizer\"\n",
      "    attribute {\n",
      "      name: \"case_change_action\"\n",
      "      s: \"LOWER\"\n",
      "      type: STRING\n",
      "    }\n",
      "    attribute {\n",
      "      name: \"is_case_sensitive\"\n",
      "      i: 0\n",
      "      type: INT\n",
      "    }\n",
      "    domain: \"\"\n",
      "  }\n",
      "  node {\n",
      "    input: \"normalized\"\n",
      "    output: \"tokenized\"\n",
      "    name: \"Tokenizer\"\n",
      "    op_type: \"Tokenizer\"\n",
      "    attribute {\n",
      "      name: \"mark\"\n",
      "      i: 0\n",
      "      type: INT\n",
      "    }\n",
      "    attribute {\n",
      "      name: \"mincharnum\"\n",
      "      i: 1\n",
      "      type: INT\n",
      "    }\n",
      "    attribute {\n",
      "      name: \"pad_value\"\n",
      "      s: \"#\"\n",
      "      type: STRING\n",
      "    }\n",
      "    attribute {\n",
      "      name: \"tokenexp\"\n",
      "      s: \"[a-zA-Z0-9_]+\"\n",
      "      type: STRING\n",
      "    }\n",
      "    domain: \"com.microsoft\"\n",
      "  }\n",
      "  node {\n",
      "    input: \"tokenized\"\n",
      "    output: \"flattened1\"\n",
      "    name: \"Flatten\"\n",
      "    op_type: \"Flatten\"\n",
      "    domain: \"\"\n",
      "  }\n",
      "  node {\n",
      "    input: \"flattened1\"\n",
      "    output: \"variable\"\n",
      "    name: \"HashingVectorizer\"\n",
      "    op_type: \"HasingVectorizer\"\n",
      "    attribute {\n",
      "      name: \"max_gram_length\"\n",
      "      i: 1\n",
      "      type: INT\n",
      "    }\n",
      "    attribute {\n",
      "      name: \"max_skip_count\"\n",
      "      i: 0\n",
      "      type: INT\n",
      "    }\n",
      "    attribute {\n",
      "      name: \"min_gram_length\"\n",
      "      i: 1\n",
      "      type: INT\n",
      "    }\n",
      "    attribute {\n",
      "      name: \"mode\"\n",
      "      s: \"TF\"\n",
      "      type: STRING\n",
      "    }\n",
      "    domain: \"\"\n",
      "  }\n",
      "  name: \"HashingVectorizer\"\n",
      "  initializer {\n",
      "    dims: 1\n",
      "    data_type: 7\n",
      "    int64_data: -1\n",
      "    name: \"shape_tensor\"\n",
      "  }\n",
      "  input {\n",
      "    name: \"input\"\n",
      "    type {\n",
      "      tensor_type {\n",
      "        elem_type: 8\n",
      "        shape {\n",
      "          dim {\n",
      "            dim_value: 1\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  output {\n",
      "    name: \"variable\"\n",
      "    type {\n",
      "      tensor_type {\n",
      "        elem_type: 1\n",
      "        shape {\n",
      "          dim {\n",
      "          }\n",
      "          dim {\n",
      "            dim_value: 1048577\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "opset_import {\n",
      "  domain: \"\"\n",
      "  version: 11\n",
      "}\n",
      "opset_import {\n",
      "  domain: \"com.microsoft\"\n",
      "  version: 1\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(model_onnx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
